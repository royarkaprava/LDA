B <- Bc
}
}
#B <- Bc
Bls[[itr]] <- B
#B <- Bc
B1 <- t(select_all_but_diag(t(B)))
}
#Update prbeta
if(!horseshoe){
# for(i in 1:m){
#   ae <- (m-1)/2 + 0.1
#   be <- sum(B[i, ]^2) + 0.1
#   if(scasig){
#     be <- sum(B[i, ]^2/d[i]^2) + 0.1
#   }
#   priorbeta[i, ] <- rep(rgamma(1, ae, be), m-1)
# }
# ae <- (m-1)*m/2 + 0.1
# be <- sum(B^2)/2 + 0.1
# if(scasig){
#   be <- sum(B1^2/matrix(d^2, m, m-1))/2 + 0.1
# }
# priorbeta <- matrix(rgamma(1, ae, be), m, m-1)
for(j in 1:m){
ae <- (m-1)/2 + 0.1
be <- sum(B[j,]^2)/2 + 0.1
if(scasig){
be <- sum(B1[j,]^2/d[j]^2/2) + 0.1
}
priorbeta[j,] <- rep(rgamma(1, ae, be), m-1)
}
#diag(priorbeta) <- 0
}
if(horseshoe){
if(scasig){
for(j in 1:m){
lamhorse[j, ] <- sqrt(1/rgamma(m-1, 1, 1/nuhorse[j, ] + B1[j,]^2/2/tauhorse^2/d[j]^2))
nuhorse[j, ] <- 1/rgamma(m-1, 1, 1+1/lamhorse[j,]^2)
}
tauhorse   <- sqrt(1/rgamma(1, m*(m-1)/2+1/2, 1/xihorse + sum(B1^2/2/lamhorse^2/matrix(d^2,m,m-1))))
xihorse   <- 1/rgamma(1, 1, 1+1/tauhorse^2)
}
if(!scasig){
for(j in 1:m){
lamhorse[j, ] <- sqrt(1/rgamma(m-1, 1, 1/nuhorse[j, ] + B1[j,]^2/2/tauhorse^2))
nuhorse[j, ] <- 1/rgamma(m-1, 1, 1+1/lamhorse[j,]^2)
}
tauhorse   <- sqrt(1/rgamma(1, m*(m-1)/2+1/2, 1/xihorse + sum(B1^2/2/lamhorse^2)))
xihorse   <- 1/rgamma(1, 1, 1+1/tauhorse^2)
}
priorbeta <- 1/(lamhorse^2 * tauhorse^2)
}
if(itr > 00){
residY = data-B%*%data
#Update d
d <- unlist(parallel::mcmapply(1:m, FUN=upD))
}
sigu <- rep(1, m)
if(scasig) {sigu<- (d)^2}
#SPre_p[[itr]] <- t(diag(m)-B)%*%diag(1/d^2)%*%t(diag(m)-B)
#Update dynamic
datamod <- diag(1/d) %*% (diag(m)-B) %*% data
for(i in 1:m){
temp       <- HMC(U, grad_U, sdden[i], L =30, delta[i, ], i, arden[i])
delta[i, ] <- temp$up#t(temp[1:J, ])
arden[i]   <- temp$arc#temp[J+1, ]
#update sigden
if(itr %% 50==0){
al <- 0.1 + J / 2
be <- 0.1 + sum((delta[i, ]) * (Amat %*% array(delta[i, ])))/2
sigden[i] <- sqrt(1 / rgamma(1, al, be))
}
}
# for(i in 1:r){
#   temp       <- HMC(Uxij, grad_Uxij, sddenxi[i], L =1, xi[, i], i, ardenxi[i])
#   xi[, i] <- temp$up#t(temp[1:J, ])
#   ardenxi[i]   <- temp$arc#temp[J+1, ]
#
#   temp       <- HMC(Uetaj, grad_Uetaj, sddeneta[i], L =1, eta[, i], i, ardeneta[i])
#   eta[, i] <- temp$up#t(temp[1:J, ])
#   ardeneta[i]   <- temp$arc#temp[J+1, ]
#
#   #update sigden
#   # if(itr %% 50==0){
#   #   al <- 0.1 + m / 2
#   #   be <- 0.1 + sum(xi[, i]^2)/2#sum((delta[i, ]) * (Amat %*% array(delta[i, ])))/2
#   #   sigxi[i] <- sqrt(1 / rgamma(1, al, be))
#   # }
#   #
#   # #update sigden
#   # #update sigden
#   # if(itr %% 50==0){
#   #   al <- 0.1 + J / 2
#   #   be <- 0.1 + sum((eta[, i]) * (Amat %*% array(eta[, i])))/2
#   #   sigeta[i] <- sqrt(1 / rgamma(1, al, be))
#   # }
# }
#
# #update sigden
# if(itr %% 1==0){
#   al <- 0.1 + m*r / 2
#   be <- 0.1 + sum(xi^2)/2#sum((delta[i, ]) * (Amat %*% array(delta[i, ])))/2
#   sigxi <- rep(sqrt(1 / rgamma(1, al, be)), r)
# }
# if(itr %% 1==0){
#   al <- 0.1 + J*r / 2
#   be <- 0.1 + sum(eta * (Amat %*% eta))/2
#   sigeta <- rep(sqrt(1 / rgamma(1, al, be)), r)
# }
# delta <- tcrossprod(xi, eta)
delta_p[[itr]] <- delta
#if(itr > noup){
#itrR <- itr-noup1
if(itr %% 100 == 0){
for(i in 1:m){
ar <- arden[i]/(itr)
#cat(ar, "for compo = ", i)
if(ar<.60){sdden[i] <- sdden[i] / 10}
if(ar>.90){sdden[i] <- sdden[i] * 10}
}
for(i in 1:r){
ar <- ardenxi[i]/(itr)
#cat(ar, "for compo = ", i)
if(ar<.45){sddenxi[i] <- sddenxi[i] / 10}
if(ar>.70){sddenxi[i] <- sddenxi[i] * 10}
ar <- ardeneta[i]/(itr)
#cat(ar, "for compo = ", i)
if(ar<.45){sddeneta[i] <- sddeneta[i] / 10}
if(ar>.70){sddeneta[i] <- sddeneta[i] * 10}
}
# if(itr > noupd){
#   ar <- ard / (itr-noupd)
#   cat(ar, "for dvec")
#   if(ar<.60){sdd <- sdd / 10}
#   if(ar>.90){sdd <- sdd * 10}
# }
# if(itr > noup){
#   for(i in 1:q){
#     ar <- arL[i]/(itr-noup)
#     #cat(ar, "for compo = ", i)
#     if(ar<.45){sdL[i] <- sdL[i] / 10}
#     if(ar>.70){sdL[i] <- sdL[i] * 10}
#   }
# }
cat(mean(arden)/(itr), "for compo")
print(mean((Bdag0[ind1] - B[ind1])^2))
# print(mean(abs(B[ind1])))
# print(mean(abs(B[ind0])))
# print(range(d))
print(sum((abs(B[ind1])>0)))
print(sum((abs(B[ind0])>0)))
TP <- sum((B[ind1]>0))
FP <- sum((B[ind0]>0))
FN <- sum((B[ind1]==0))
TN <- sum((B[ind0]==0))
print((TP*TN - FP*FN) / (sqrt(TP+FP)*sqrt(TP+FN)*sqrt(TN+FP)*sqrt(TN+FN)))
}
#print(range(abs(SPre[t(index)])))
#}
# print(range(SPre))
#print(range(delta))
#print(itr)
#toc()
}
M2 <- 10000
M1 <- 5000
index <- as.matrix(combinat::combn(1:m, 2))
pdmates  <- matrix(0, m^2, M2-M1+1)
pdmates0 <- matrix(0, ncol(index), M2-M1+1)
# Blsp <- Reduce('+', Bls[M1:M2])/(M2-M1+1)
#
# pdmatt <- Bdag0[t(index)]
# ind1 <- which(pdmatt==1)
# ind0 <- which(pdmatt==0)
# range(abs(Lvecc[which(Lvecc!=0)]))
#
# thl <- min(abs(Lvecc[which(Lvecc!=0)])) + diff(range(abs(Lvecc[which(Lvecc!=0)])))*(1:10)/10
#thl <- c(thl[1]-thl[1]*(3:1)/4, thl)
# TP <- rep(0, 10)
# FP <- rep(0, 10)
for(i in M1:M2){
pdmates[, i-M1+1] <- (abs(Bls[[i]])>0) #* temp #/ sqrt(diagS[index[1, ]]*diagS[index[2, ]])
}
Bb <- matrix((rowMeans(pdmates) > 0.9), m, m)
TP <- sum((Bb[ind1]>0))
FP <- sum((Bb[ind0]>0))
FN <- sum((Bb[ind1]==0))
TN <- sum((Bb[ind0]==0))
(TP*TN - FP*FN) / (sqrt(TP+FP)*sqrt(TP+FN)*sqrt(TN+FP)*sqrt(TN+FN))
data<-read.csv("H:/Documents/MiM/RestingState_concatenated_23Sep1.csv", header = T)
segscores <-  data[, 2:11]
mat <- matrix(0, nrow(data), 2)
mat[which(data$Group==1), 1] <- 1
mat[which(data$Group==3), 2] <- 1
behav <- cbind(data[, c("gaitspeed_400m", "sex_mr")], "grp1"=mat[,1], "grp3"=mat[,2])  #"sex_mr"
#I always like to make the middle group baseline for better inference
library(mdatools)
m = pls(pca.mvreplace(behav), pca.mvreplace(segscores), 7, scale = TRUE, cv = 1)
summary(m$coeffs)
View(pdmates0)
View(pdmates0)
??gls
setwd("H:/Documents/GitHub/LDA/Codes")
data <- read.table("fev1.txt", quote="\"", comment.char="")
colnames(data) = c("ID", "Height", "Age", "Initial Height", "Initial Age", "LogFEV1")
data_new <- data
data_new$ID <- factor(data_new$ID, ordered = T)
data <- read.table("H:/Documents/GitHub/LDA/Codes/Data on seizure counts.txt", quote="\"", comment.char="")
library(tidyr)
data_long <- gather(data, Week, measurement, V5:V8, factor_key=TRUE)
data_long <- data_long[order(data_long$V1), ]
####
colnames(data_long)[4] = "Baseline"
colnames(data_long)[1] = "Subject"
colnames(data_long)[2] = "Treatment"
colnames(data_long)[3] = "Age"
data_new = data_long
data_new$Week <- as.character(data_new$Week)
#data_new$Week[grep("V4", data_long$Week)] = "0"
data_new$Week[grep("V5", data_long$Week)] = "1"
data_new$Week[grep("V6", data_long$Week)] = "2"
data_new$Week[grep("V7", data_long$Week)] = "3"
data_new$Week[grep("V8", data_long$Week)] = "4"
data_new$Week <- as.numeric(data_new$Week)
data_new$Treatment <- as.factor(data_new$Treatment)
data_new$measurement <- log(data_new$measurement)
data_new$Baseline <- log(data_new$Baseline)
fm1 <- gls(measurement ~ Week, data_new,
correlation = corSymm(form = ~ 1 | Subject))
library(nlme)
fm1 <- gls(measurement ~ Week, data_new,
correlation = corSymm(form = ~ 1 | Subject))
##Generalized least square############
fm1 <- gls(measurement ~ Week, data_new,
correlation = corAR1(form = ~ 1 | Subject))
data <- read.table("H:/Documents/GitHub/LDA/Codes/Data on seizure counts.txt", quote="\"", comment.char="")
library(tidyr)
data_long <- gather(data, Week, measurement, V5:V8, factor_key=TRUE)
data_long <- data_long[order(data_long$V1), ]
####
colnames(data_long)[4] = "Baseline"
colnames(data_long)[1] = "Subject"
colnames(data_long)[2] = "Treatment"
colnames(data_long)[3] = "Age"
data_new = data_long
data_new$Week <- as.character(data_new$Week)
#data_new$Week[grep("V4", data_long$Week)] = "0"
data_new$Week[grep("V5", data_long$Week)] = "1"
data_new$Week[grep("V6", data_long$Week)] = "2"
data_new$Week[grep("V7", data_long$Week)] = "3"
data_new$Week[grep("V8", data_long$Week)] = "4"
data_new$Week <- as.numeric(data_new$Week)
data_new$Treatment <- as.factor(data_new$Treatment)
data_new$measurement <- log(data_new$measurement)
data_new$Baseline <- log(data_new$Baseline)
library(nlme)
res <- lme(measurement ~ Week, random = ~1|Subject, data = data_new)
data <- read.table("H:/Documents/GitHub/LDA/Codes/Data on seizure counts.txt", quote="\"", comment.char="")
library(tidyr)
data_long <- gather(data, Week, measurement, V5:V8, factor_key=TRUE)
data_long <- data_long[order(data_long$V1), ]
####
colnames(data_long)[4] = "Baseline"
colnames(data_long)[1] = "Subject"
colnames(data_long)[2] = "Treatment"
colnames(data_long)[3] = "Age"
data_new = data_long
data_new$Week <- as.character(data_new$Week)
#data_new$Week[grep("V4", data_long$Week)] = "0"
data_new$Week[grep("V5", data_long$Week)] = "1"
data_new$Week[grep("V6", data_long$Week)] = "2"
data_new$Week[grep("V7", data_long$Week)] = "3"
data_new$Week[grep("V8", data_long$Week)] = "4"
data_new$Week <- as.numeric(data_new$Week)
data_new$Treatment <- as.factor(data_new$Treatment)
data_new$measurement <- log(data_new$measurement+1)
data_new$Baseline <- log(data_new$Baseline+1)
library(nlme)
res <- lme(measurement ~ Week, random = ~1|Subject, data = data_new)
res.AR1 <- update(res, correlation = corAR1())
res.ARMA11 <- update(res, corr = corARMA(p = 1, q = 1))
fm1 <- lme(measurement ~ Week, random = ~1|Subject, data = data_new)
ACF(fm1, maxLag = 3)
ctrl <- lmeControl(opt='optim'); #lmeControl(msMaxIter = 1000, msMaxEval = 1000)
res <- lme(measurement ~ Week, random = ~Week|Subject,control = ctrl, data = data_new)
##Generalized least square############
fm1 <- gls(measurement ~ Week, data_new,
correlation = corAR1(form = ~ 1 | Subject))
fm1 <- gls(measurement ~ Week, data_new,
correlation = corSymm(form = ~ 1 | Subject))
res <- lme(measurement ~ Week, random = ~1+Week|V1, data = data_new)
res <- lme(measurement ~ Week, random = ~1+Week|Subject, data = data_new)
res <- lme(measurement ~ Week, random = ~Week|Subject, data = data_new)
library(nlme)
head(Orthodont)
res1 <- lme(distance ~ age, random = ~ age | Subject, data=Orthodont)
summary(res1)
############Two-stage model#####
res.list <- lmList(distance ~ age, data=Orthodont)
plot(augPred(res.list), grid=TRUE)
# extract the estimated model coefficients (intercepts and slopes) and the corresponding variance-covariance
b <- lapply(res.list, coef)
V <- lapply(res.list, vcov)
estm <- rep(c("intercept","slope"), length(b))
subj <- rep(names(b), each=2)
#one long vector with the model coefficients and the corresponding block-diagonal variance-covariance matrix
library(metafor)
b <- unlist(b)
V <- bldiag(V)
#multivariate meta-analysis with the model coefficients
#The V matrix contains the variances and covariances of the sampling errors. We also allow for heterogeneity in the true outcomes (i.e., coefficients) and allow them to be correlated (by using an unstructured variance-covariance matrix for the true outcomes).
res2 <- rma.mv(b ~ estm - 1, V, random = ~ estm | subj, struct="UN")
res2
library(nlme)
#head(Orthodont)
data <- read.table("fev1.txt", quote="\"", comment.char="")
colnames(data) = c("ID", "Height", "age", "Initial Height", "Initial Age", "LogFEV1")
data_new <- data
data_new$ID <- factor(data_new$ID, ordered = T)
res1 <- lme(LogFEV1 ~ age, random = ~ age | Subject, data=data_new)
library(nlme)
#head(Orthodont)
data <- read.table("fev1.txt", quote="\"", comment.char="")
colnames(data) = c("Subject", "Height", "age", "Initial Height", "Initial Age", "LogFEV1")
data_new <- data
data_new$Subject <- factor(data_new$Subject, ordered = T)
res1 <- lme(LogFEV1 ~ age, random = ~ age | Subject, data=data_new)
summary(res1)
############Two-stage model#####
res.list <- lmList(LogFEV1 ~ age, data=data_new)
res.list <- lmList(distance ~ age, data=Orthodont)
head(Orthodont)
library(nlme)
#head(Orthodont)
data <- read.table("fev1.txt", quote="\"", comment.char="")
colnames(data) = c("Subject", "Height", "age", "Initial Height", "Initial Age", "LogFEV1")
data_new <- data[, c(6, 3, 1, 4)]
data_new$Subject <- factor(data_new$Subject, ordered = T)
res1 <- lme(LogFEV1 ~ age, random = ~ age | Subject, data=data_new)
summary(res1)
############Two-stage model#####
res.list <- lmList(LogFEV1 ~ age, data=data_new)
?lmList
library(nlme)
#head(Orthodont)
data <- read.table("fev1.txt", quote="\"", comment.char="")
colnames(data) = c("Subject", "Height", "age", "Initial Height", "Initial Age", "LogFEV1")
data_new <- data#[, c(6, 3, 1, 4)]
data_new$Subject <- factor(data_new$Subject, ordered = T)
res1 <- lme(LogFEV1 ~ age, random = ~ age | Subject, data=data_new)
summary(res1)
############Two-stage model#####
res.list <- lmList(LogFEV1 ~ age | Subject, data=data_new)
plot(augPred(res.list), grid=TRUE)
# extract the estimated model coefficients (intercepts and slopes) and the corresponding variance-covariance
b <- lapply(res.list, coef)
V <- lapply(res.list, vcov)
estm <- rep(c("intercept","slope"), length(b))
subj <- rep(names(b), each=2)
#one long vector with the model coefficients and the corresponding block-diagonal variance-covariance matrix
library(metafor)
b <- unlist(b)
V <- bldiag(V)
#multivariate meta-analysis with the model coefficients
#The V matrix contains the variances and covariances of the sampling errors. We also allow for heterogeneity in the true outcomes (i.e., coefficients) and allow them to be correlated (by using an unstructured variance-covariance matrix for the true outcomes).
res2 <- rma.mv(b ~ estm - 1, V, random = ~ estm | subj, struct="UN")
res2
gtsummary::tbl_regression(res1)
summary(res1)
summary(res2)
estm
b
?rma.mv
lme(b ~ estm - 1, random = ~ estm | subj, struct="UN")
lme(b ~ estm - 1, random = ~ estm | subj)
lme(b ~ estm - 1, random = ~ estm | subj, na.omit=T)
?lme
lme(b ~ estm - 1, random = ~ estm | subj, na.action=na.omit)
summary(lme(b ~ estm - 1, random = ~ estm | subj, na.action=na.omit))
summary(res1)
fm1 <- gls(b ~ estm - 1,
correlation = corSymm(form = ~ 1 | subj), na.action=na.omit)
summary(fm1)
resgls1 <- gls(LogFEV1 ~ age, data_new,
correlation = corSymm(form = ~ 1 | Subject))
summary(resgls1)
library(nlme)
#head(Orthodont)
data <- read.table("fev1.txt", quote="\"", comment.char="")
colnames(data) = c("Subject", "Height", "age", "Initial Height", "Initial Age", "LogFEV1")
data_new <- data#[, c(6, 3, 1, 4)]
data_new$Subject <- factor(data_new$Subject, ordered = T)
res1 <- lme(LogFEV1 ~ age, random = ~ age | Subject, data=data_new)
#summary(res1)
resgls1 <- gls(LogFEV1 ~ age, data_new,
correlation = corSymm(form = ~ 1 | Subject))
############Two-stage model#####
res.list <- lmList(LogFEV1 ~ age | Subject, data=data_new)
length(unique(data_new$Subject))
length(res.list)
res.list[[1]]
b <- lapply(res.list, coef)
V <- lapply(res.list, vcov)
estm <- rep(c("intercept","slope"), length(b))
subj <- rep(names(b), each=2)
subj
b
b <- unlist(b)
b
subj
V <- bldiag(V)
#multivariate meta-analysis with the model coefficients
#The V matrix contains the variances and covariances of the sampling errors. We also allow for heterogeneity in the true outcomes (i.e., coefficients) and allow them to be correlated (by using an unstructured variance-covariance matrix for the true outcomes).
res2 <- rma.mv(b ~ estm - 1, V, random = ~ estm | subj, struct="UN")
summary(res1)
summary(res2)
data <- read.table("fev1.txt", quote="\"", comment.char="")
colnames(data) = c("ID", "Height", "Age", "Initial Height", "Initial Age", "LogFEV1")
data_new <- data
data_new$ID <- factor(data_new$ID, ordered = T)
ctrl <- lmeControl(msMaxIter = 1000, msMaxEval = 1000)
library(nlme)
res <- lme(LogFEV1 ~ Age, random = ~1+Age|ID, data = data_new)
data <- read.table("H:/Documents/GitHub/LDA/Codes/Data on seizure counts.txt", quote="\"", comment.char="")
library(tidyr)
data_long <- gather(data, Week, measurement, V5:V8, factor_key=TRUE)
data_long <- data_long[order(data_long$V1), ]
####
colnames(data_long)[4] = "Baseline"
colnames(data_long)[1] = "Subject"
colnames(data_long)[2] = "Treatment"
colnames(data_long)[3] = "Age"
data_new = data_long
data_new$Week <- as.character(data_new$Week)
#data_new$Week[grep("V4", data_long$Week)] = "0"
data_new$Week[grep("V5", data_long$Week)] = "1"
data_new$Week[grep("V6", data_long$Week)] = "2"
data_new$Week[grep("V7", data_long$Week)] = "3"
data_new$Week[grep("V8", data_long$Week)] = "4"
data_new$Week <- as.numeric(data_new$Week)
data_new$Treatment <- as.factor(data_new$Treatment)
data_new$measurement <- log(data_new$measurement+1)
data_new$Baseline <- log(data_new$Baseline+1)
library(nlme)
res <- lme(measurement ~ Week, random = ~1|Subject, data = data_new)
res <- lme(measurement ~ Week, random = ~as.factor(Week)|Subject, data = data_new)
fm1 <- gls(measurement ~ Week, data_new,
correlation = corSymm(form = ~ 1 | Subject))
summary(fm1)
summary(res)
?gls
res <- lme(measurement ~ Week, random = ~1+as.factor(Week)|Subject, data = data_new)
summary(res)
summary(fm1)
res <- lme(measurement ~ Week, random = ~as.factor(Week)|Subject, data = data_new)
summary(res)
summary(fm1)
data <- read.table("Treatment of Lead Exposed Children Trial.txt", quote="\"", comment.char="")
#Wide format analysis
fit <- lm(cbind(V3,V4,V5,V6)~V2, data=data)
idata <- data.frame(Week = factor(c("V3","V4","V5","V6")))
idata
rmaov <- car::Anova(fit, idata=idata, idesign = ~Week,  type=3)
rmaov
#By default, because we have used a multivariate DV, this will show a so-called MANOVA (Multivariate ANalysis of VAriance). To obtain an ANOVA, we need to set the multivariate argument in the summary function to
summary(rmaov, multivariate=FALSE)
#In long format analysis in afex package
library(tidyr)
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
data_long <- gather(data, Week, measurement, V3:V6, factor_key=TRUE)
data_long <- data_long[order(data_long$V1), ]
data <- read.table("Treatment of Lead Exposed Children Trial.txt", quote="\"", comment.char="")
#Wide format analysis
fit <- lm(cbind(V3,V4,V5,V6)~V2, data=data)
idata <- data.frame(Week = factor(c("V3","V4","V5","V6")))
idata
rmaov <- car::Anova(fit, idata=idata, idesign = ~Week,  type=3)
rmaov
#By default, because we have used a multivariate DV, this will show a so-called MANOVA (Multivariate ANalysis of VAriance). To obtain an ANOVA, we need to set the multivariate argument in the summary function to
summary(rmaov, multivariate=FALSE)
#In long format analysis in afex package
library(tidyr)
# The arguments to gather():
# - data: Data object
# - key: Name of new key column (made from names of data columns)
# - value: Name of new value column
# - ...: Names of source columns that contain values
# - factor_key: Treat the new key column as a factor (instead of character vector)
data_long <- gather(data, Week, measurement, V3:V6, factor_key=TRUE)
data_long <- data_long[order(data_long$V1), ]
data_new=data_long
res <- lme(measurement ~ Week, random = ~as.factor(Week)|V1, data = data_new)
fm1 <- gls(measurement ~ Week, data_new,
correlation = corSymm(form = ~ 1 | V1))
summary(fm1)
summary(res)
res <- lme(measurement ~ Week, random = ~as.factor(Week)|V1, data = data_new, REML=F)
res <- lme4(measurement ~ Week, random = ~as.factor(Week)|V1, data = data_new)
library(lmer)
res <- lme4(measurement ~ Week, random = ~as.factor(Week)|V1, data = data_new)
res <- lmer(measurement ~ Week, random = ~as.factor(Week)|V1, data = data_new)
?lmer
library(lme4)
res <- lmer(measurement ~ Week, random = ~as.factor(Week)|V1, data = data_new)
res <- lmer(measurement ~ Week+(as.factor(Week)|V1), data = data_new)
detach("package:igraph", unload = TRUE)
